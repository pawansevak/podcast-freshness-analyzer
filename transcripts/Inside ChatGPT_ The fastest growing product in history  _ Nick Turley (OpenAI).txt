---
podcast: Lenny's Podcast
episode: Inside ChatGPT
guest: Nick Turley
category: build_ai_products
---

00:00:00 - 00:00:43
You were a product leader at Dropbox,  then Instacart. Now, you're the PM of the most consequential product in history. I didn't know what I would do here because it was a research lab. My first task was I  fix the blinds, or something like that. When someone offers you a rocket  ship, don't ask which seat. We set out to build a super assistant. It  was supposed to be a hackathon code base. What was it called before? It was going to be Chat with GPT-3.5 because we really didn't think it  was going to be a successful product. And then Sam Altman is just like, "Hey, let me tweet about it." This is a pattern with AI, you won't know what to polish until after  you ship. My dream is that we ship daily. By the time people hear this, they're  going to have their hands on GPT-5. About 10% of the world population uses every  week. With scale comes responsibility. It just feels a little bit more alive, a bit  more human. This model has taste. Kevin Weil, your CPO, said to ask you about this  principle of, "Is it maximally accelerated?"


00:00:43 - 00:01:33
I just really want to jump to the punchline,  "Why can't we do this now?" I always felt like part of my role here is to just set  the pace and the resting heartbeat. Everyone is always wondering, "Is Chat  the future of all of this stuff?" Chat was the simplest way to ship at that time.  I'm baffled by how much it took off, even more baffled by how many people have copied. ChatGPT is now driving more traffic to my newsletter than Twitter. That is the type of capability that has been incredibly retentive. I've been really  excited about what we've been doing in search. Can you give us a peek into  where this goes long-term? ChatGPT feels a little bit like  MS-DOS. We haven't built Windows yet, and it will be obvious once we do. Today, my guest is Nick Turley. Nick is Head of ChatGPT at OpenAI. He  joined the company three years ago, when it was still primarily a research lab. He  helped come up with the idea of ChatGPT and took it from 0 to over 700 million weekly active  users, billions in revenue, and arguably the


00:01:33 - 00:02:28
most successful and impactful consumer software  product in human history. Nick is incredible. He's been very much under the radar. This is the first  major podcast interview that he has ever done, and you are in for a treat. We talk about all  the things, including the just launched GPT-5. A huge thank you to Kevin Weil, Claire Vo,  George O'Brien, Joanne Jang, and Peter Deng for suggesting topics for this conversation. If  you enjoy this podcast, don't forget to subscribe and follow it in your favorite podcasting app, or  YouTube. And if you become an annual subscriber of my newsletter, you get a year free of a bunch  of incredible products, including Lovable, Replit, Bolt, n8n, Linear, Superhuman, Descript,  Wispr Flow, Gamma, Perplexity, Warp, Granola, Magic Patterns, Raycast, ChatPRD, and Mobbin.  Check it out lennysnewsletter.com and click, "bundle". With that, I bring you Nick Turley. This episode is brought to you by Orkes, the company behind open source Conductor, the  orchestration platform powering modern enterprise


00:02:28 - 00:03:28
apps and agentic workflows. Legacy automation  tools can't keep pace. Siloed, low-code platforms, outdated process management, and disconnected  API tooling falls short in today's event-driven, AI-powered agentic landscape. Orkes changes  this. With Orkes Conductor, you gain an agentic orchestration layer that seamlessly  connects humans, AI agents, APIs, microservices, and data pipelines in real time at enterprise  scale, visual and code-first development, built-in compliance, observability, and rock-solid  reliability, ensure workflows evolve dynamically with your needs. It's not just about automating  tasks, it's orchestrating autonomous agents and complex workflows to deliver smarter outcomes  faster. Whether modernizing legacy systems or scaling next-gen, AI-driven apps, Orkes  accelerates your journey from idea to production. Learn more and start building  at orkes.io/lenny, that's orkes.io/lenny. This episode is brought to you by Vanta, and  I am very excited to have Christina Cacioppo,


00:03:28 - 00:04:26
CEO and co-founder of Vanta, joining  me for this very short conversation. Great to be here. Big fan of the  podcast and the newsletter. Vanta is a longtime sponsor of the show,  but for some of our newer listeners, what does Vanta do and who is it for? Sure. So we started Vanta in 2018, focused on founders, helping them start to build  out their security programs and get credit for all of that hard security work with compliance  certifications, like SOC 2 or ISO 27001. Today, we currently help over 9,000 companies, including  some startup household names, like Atlassian, Ramp, and LangChain, start and scale their  security programs, and ultimately build trust by automating compliance, centralizing  GRC, and accelerating security reviews. That is awesome. I know from experience that these  things take a lot of time and a lot of resources, and nobody wants to spend time doing this. That is very much our experience, but before the company, and some extent, during it,  but the idea is, with automation, with AI,


00:04:26 - 00:05:22
with software, we are helping customers  build trust with prospects and customers in an efficient way. And our joke, we started  this compliance company so you don't have to. We appreciate you for doing that, and you have  a special discount for listeners. They can get $1,000 off Vanta at vanta.com/lenny, that's  vanta.com/lenny for $1,000 off Vanta. Thanks for that, Christina. Thank you! Nick, thank you so much for joining  me, and welcome to the podcast. Thanks for having me, Lenny. I already had a billion questions I wanted to ask you, and then you guys decided to launch  GPT-5 the week that we're recording this. So, now, I have at least 2 billion questions for you.  I hope you have a lot of time. First of all, just congrats on the launch. It's coming tomorrow,  the day after recording this. Just congrats. How are you feeling? I imagine this is an ungodly  amount of work and stress. How are you doing? It's a busy week, but we've been  working on this for a while,


00:05:26 - 00:06:24
so it also feels really good to get it out. So, by the time people hear this, they're going to have their hands on GPT-5, the newest  ChatGPT. What's the simplest way to just understand what this is, what it unlocks, what  people can do with it? Give us the pitch. I'm so excited about GPT-5. I think for most  people, it's going to feel like a real step change. If you're the average ChatGPT user, and  we have 700 million of them this week, you've probably been on GPT-4o for a while. You probably  don't even think about the model that powers the product. And GPT-5, it just feels categorically  different. I'll talk about a lot of the specifics, but at the end of the day, the vibes are good,  at least we feel that way. We hope that users feel the same. And increasingly, that is the thing  that I think most people notice, right? They don't look at the academic benchmarks. They don't look  at evaluations. They try the model and see what it feels like. And just on that dimension alone,  I'm so excited. I've been using it for a while,


00:06:24 - 00:07:32
but it is also the smartest, most useful, and  fastest frontier model that we've ever launched. On pure SMARTs, one way to look at that is  academic benchmarks on many of the standard ones, whether or not it's math, or reasoning, or just  raw intelligence. This model is state of the art. I'm especially excited about its performance  on coding, whether or not that's SWE-bench, which is a common benchmark, or actually front-end  coding is really, really good as well, and that's an area where I feel like there's the true step  change improvement in GPT-5. But really, no matter how you measure the SMARTs, it's quite remarkable,  and I think people are going to feel the upgrade, especially if they weren't using o3 already. And the second thing beyond SMARTs is it's just really useful. Coding is one axis of utility,  whether or not you have coding questions or you're vibe coding an app, but it's also a  really good writer. I write for a living, internally, externally. I just wrote a big blog  post that we published Monday, and this thing


00:07:33 - 00:08:30
is such an incredible editor. And compared to some  of the older models, it's got taste, which I think is really exciting. And to me, that's something  that is truly useful in my day-to-day. And there's a bunch of other areas, like it's state of the  art on health, which is useful when you need it, but again, the thing you can't really express  in use cases or data is the vibe of the model. And it just feels a little bit more alive, a bit  more human in a way that is hard to articulate until you try it. So, feel good about that. And yeah, as mentioned, it's faster. It thinks, too, just like o3 did, but you don't have  to manually tell it to do that. It'll just dynamically decide to think when it needs to. And  when it doesn't need to think, it just responds instantly, and that ends up feeling quite a bit  faster than using o3 did. And then maybe the thing that's most exciting is that we're making it  available for free, and that's one of those things


00:08:30 - 00:09:28
that I feel like we can uniquely do at OpenAI.  Because many companies, I think, if they have a subscription model like us, they would gate it  behind their paid plan. And for us, if we can scale it, we will, and that just feels awesome.  We did that with 4o as well. So, everyone is going to be able to try GPT-5 tomorrow, hopefully. How long does something like this take? I don't know if there's a simple answer to this, but just  how long have you guys been working on GPT-5? We've been working on it for a while. You  can view GPT-5 as a culmination of a bunch of different efforts. We had a reasoning tech, we had  a more classic post-screening methodologies, and therefore, it's really hard to put a beginning on  it, but it really is the end point of a bunch of different techniques that we began for a while. Can you give us a peek into the vision for where ChatGPT is going, GPT in general is going?  If you look at on the surface, it's been the same idea with a much smarter brain for a long  time. I'm curious where this goes long-term.


00:09:28 - 00:10:24
So, to maybe back up a bit, now, you  think of ChatGPT as, "Is this going to be ubiquitous product?" Again, about 10%  of the world population uses every week. Holy shit. I think we have 5 million business customers now. It's an established category in its own right.  But really, when we started, we set out to build a super assistant, that's how we talked about  it at the time. In fact, the code base that we use is called SA Server. It was supposed to be  a hackathon code base, but things always turn out a little bit differently. So, yeah, in some  ways, that is still the vision. The reason I don't talk about it more than I do is because I think  assistant is a bit limiting in terms of the mental model we're trying to create. You think of this  very personified human thing, maybe utilitarian, maybe a... And frankly, having an assistant is  not particularly relatable to most people, unless they're in Silicon Valley and they're a manager,  or something like that. So it's imperfect.


00:10:24 - 00:11:25
But really, what we envision is this entity that  can help you with any task, whether or not that's at home, or at work, or at school, really any  context, and it's an entity that knows what you're trying to achieve. So, unlike ChatGPT today, you  don't have to describe your problem in menu to detail because it already stands your overarching  goals and has context on your life, et cetera. So, that's one thing that we're really excited about.  The inverse of giving it more inputs on your life is giving it more action space. So, we're really  excited to allow it to do, over time, what a smart, empathetic human with a computer could  do for you. And I think the limit of the types of problems that you can solve for people, once  you give it access to tools like that, is very, very different than what you might be able to  do in a chatbot today. So, that's more outputs. And I often think, "Okay, I'm a general  intelligence. What happened if I became


00:11:25 - 00:12:17
Lenny's intern, or something?" And I wouldn't  be particularly effective despite having both of those attributes that I just mentioned, and  it's because I think this idea of building a relationship with this technology is also  incredibly important. So, that's maybe the third piece that I'm excited about is building  a product that can truly get to know you over time. And you saw us launch some of those things  with improved memory earlier this year, and that's just the beginning of what we're hoping to do so  that it really feels like this is your AI. So, I don't know if supersystem is still the right  exact analogy, but I think people just think of it as their AI. And I think we can put one  in everyone's pocket and help them solve real problems, whether or not that's becoming healthy,  whether or not that's starting a business, whether or not that's just having a second  opinion on anything. There's so many different problems that you can help with people in their  daily life, and that's what motivates me.


00:12:17 - 00:13:09
So an interesting between the lines that  I'm reading here is the vision is for it to be an assistant for people not to replace  people. It feels like a really important piece of the puzzle. Maybe just talk about that. AI is really scary to people, and I understand there's decades of movies on AI that have a  certain mental model baked in. And even if you just look at the technology today, everyone, I  think, has this moment where the AI does something that was really deeply personal to them and you're  thought, "Hey, AI can never do that." For me, it was weird music theory things where I was like,  "Wow, this thing actually understands music better than I do," and that's something I'm passionate  about. And so it's naturally scary. And I think the thing that's been really important to us for  a long time is to build something that feels like it's helpful to you, but you're in the driver's  seat, and that's even more important as the


00:13:10 - 00:13:57
stuff becomes agentic, the feeling of being  in control, and that can be small things. We built this way of watching what the AI is doing  when it's in agent mode. And it's not that you actually are going to watch it the whole time,  but it gives you a mental model and makes you feel in control in the same way that, when you're  in a Waymo, you get that screen, for those of you who've tried Waymo. You can see the other cars.  It's not like you're going to actually watch, but it gives you the sense that you know  how this thing works and what's happening, or we always check with you to confirm  things. It's a little bit annoying, but it puts you in the driver's seat, which is  important. And for that reason, we always view technology and the technology that we build as  something that amplifies what you're capable of, rather than replacing it, and that becomes  important as the deck gets more powerful. Okay. So you mentioned the beginnings of ChatGPT.  I was reading in a different interview. So you


00:13:58 - 00:14:54
joined OpenAI. ChatGPT was just this internal  experimental project that was basically a way to test GPT-3.5, and then Sam Altman is  just like, "Hey, let me tweet about it, maybe see if people find this interesting," yada  yada, yada. It's the most successful consumer product in history, I think both in growth rate  in users and revenue, and just absurd. Can you give us a glimpse into that early period before  it became something everyone is obsessed with? Yeah. So we had decided that we wanted to do  something consumer-facing, I think, right around the time that GPT-4 finished training, and it  was actually mainly for a couple of reasons. We already had a product out there, which was our  developer product. That's actually what I came in to help with initially, and that has been amazing  for the mission. In fact, it's grown up. And now, it's the OpenAI platform with, I don't know, 4  million developers, I think. But at that time, it was early stage, and we were running  into some constraints with it because


00:14:56 - 00:15:56
there was two problems. One, you couldn't iterate  very quickly because, every time you would change the model, you'd break everyone's app.  So, it was really hard to try things. And then the other thing was that it was really  hard to learn because the feedback we would get was the feedback from the end user to the  developer to us. So it was very disintermediated, and we were excited to make fast progress towards  AGI and it just felt like we needed a more direct relationship with consumers. So we were trying to  figure out where to start. And in classic OpenAI fashion, especially back then, we put together  a hackathon of enthusiasts of just hacking on GPT-4 to see what awesome stuff we could create  and maybe ship to users, and everyone's idea was some flavor of a super assistant. They were more  specific ideas, like we had a meeting bot that would call into meetings, and the vision was maybe  it would help you run the meeting over time. We had a coding tool, which full circle now, probably  ahead of its time. And the challenge was that we


00:15:56 - 00:16:50
tested those things, but every time we tested  these more bespoke ideas, people wanted to use it for all this other stuff because it's just  a very, very generically powerful technology. So, after a couple of months of prototyping,  we took that same crew of volunteers, and it was truly a volunteer group, right? We  had someone from the supercomputing team who had built an iOS app before. We had someone on the  research team who had written some backend code in their life. They were all part of this initial  ChatGPT team, and we decided to ship something open-ended because we just wanted a real use case  distribution. And this is a pattern with AI, I think, where you really have to ship to understand  what is even possible and what people want, rather than being able to reason about that a  priori. So, ChatGPT came together at the end because we just wanted the learnings as soon  as we could, and we shipped it right before the holiday thinking we would come back and get  the data and then wind it down. And obviously,


00:16:50 - 00:17:47
that part turned out super differently because  people really liked the product as is. So I remember going through the motions of  like, "Oh, man, dashboard is broken. Oh, wait, people are liking it. I'm sure it's just going  viral and stuff is going to die down," to like, "Oh, wow, people are retaining, but I  don't understand why." And then eventually, we fell into product development mode,  but it was a little bit by accident. Wow. I did not know that ChatGPT emerged  out of a hackathon project. Definitely the most successful hackathon project. I like to tell this story when we do our hackathons because I really do want people  to feel like they can ship their idea, and it's certainly been true in the past,  and we'll continue to make it true. If you don't want to share these things,  but I wonder who that team was. The team is largely still around. Some of  the researchers working on GPT-5, actually, were always part of the ChatGPT team. Engineers  are still around. Designers are still around. I'm


00:17:48 - 00:18:44
still here, I guess. So, yeah, you've got the team  still running things, but obviously, we've grown up tremendously, and we've had to because with  scale comes responsibility. And we're going to hit a billion users soon and you have to begin acting  in a way that is appropriate to that scale. Okay. So let me spend a little time there. So,  I don't know if this is 100% true, but I believe it is that ChatGPT is the fastest growing, most  successful consumer product in history. Also, the most impactful on people's lives. It feels  like it's just part of the ether of society now. It's just my wife talks to it. Every question  I have, I go to it, voice mode. My wife is just like, "Let me check with ChatGPT." It's just such  a part of our life now, and I think it's still early. So many people don't even know what the  hell is going on. Just as someone leading this, do you ever just take a moment to reflect  and think about just like, "Holy shit"?


00:18:45 - 00:19:50
I have to. It's quite humbling to get to run a  product like that, and I have to pinch myself very frequently, and I also have to sometimes sit back  and just think, which is really hard when things are moving so quickly. I love setting a fast  pace at the company, but in order to do that with confidence, I need at least one day every week  that I'm entirely unplugged and I'm just thinking about what to do and process the week, et cetera. And the other thing is I've never ever worked on a product that is so empirical in its nature  where, if you don't stop, and watch, and listen to what people are doing, you're going to miss  so much, both on the utility and on the risks, actually. Because normally, by the time you ship a  product, you know what it's going to do. You don't know if people are going to like it, that's always  empirical, but you know what it can do. And with AI, because I think so much of it is emergent,  you actually really need to stop and listen


00:19:50 - 00:20:43
after you launch something and then iterate  on the things people are trying to do and on the things that aren't quite working yet. So, for  that reason alone, I think it's very important to take a break and just watch what's going on. Okay. So you take a day off every week... not off. Okay, that's not the right way to put it.  You take a day of thinking time, deep work. I need it. Yeah, yeah, yeah. And I  need to hard unplug on a Saturday, or something like that. Obviously- On a Saturday [inaudible 00:20:16]. But it's just not possible otherwise.  This has been a giant marathon for three years now. Yeah. Like a sprint marathon. Sprint marathon, that's right, or interval  training, or something. I don't know how to exactly describe the OpenAI launch cadence,  but you've got to set yourself up in a way that is sustainable. Even if this wasn't AI and it  didn't have the interesting attributes that I just mentioned, I think you would need to do that. But  especially with AI, it's important to go watch.


00:20:45 - 00:21:46
So, along those lines, I talked to a bunch  of people that work with you, that work at OpenAI. Joanne specifically said that urgency  and pace are a big part of how you operate, that that's just something you find really  important, to create urgency within the team constantly, even when you are the fastest  growing product in history, growing like crazy. Talk about just your philosophy on the  importance of pace and urgency on teams. Well, it's nice of her to say that. Two things,  with ChatGPT, when we decided to do it, we had been prototyping for so long and I was just like,  "In 10 days, we're going to ship this thing," and we did. So, that was maybe a moment in time thing  where I just really wanted to make sure that we go learn something. Ever since then, I spent so much  time thinking about why ChatGPT became successful in the first place, and I think there was some  element of just doing things where there was many other companies that had technology in the  LLM space that just never got shipped. And I just


00:21:46 - 00:22:41
felt like, of all the things we could optimize  for, learning as fast as possible is incredibly important. So I just started rallying people  around that, and that took different forms. For a while, when we were of that size, I just  ran this daily release sync and had everyone who was required to make a decision in it, and we  would just talk about what to do and to pivot from yesterday, et cetera. Obviously, at some point,  that doesn't scale, but I always felt like part of my role here, obviously, was to think about the  direction of the product, but also to just set the pace and the resting heartbeat for our teams.  And again, this is important anywhere, but it's especially important when the only way to find out  what people like and what's valuable is to bring it into the external world. So, for that reason,  I think it's become a superpower of OpenAI, and I'm glad that Joanne thinks that I had some part  in that, but it really has taken a village. I love this phrase, "the resting  heart rate of your team".


00:22:41 - 00:23:38
That's such a perfect metaphor of just the pace  of being equivalent to your resting heart rate. I actually learned that at Instacart, when  I showed up there, because we were in the pandemic and it was all hands on deck. For a  while, there was this... I think there was a company-wide stand-up because we disbanded all  teams. We were just trying to keep the site up. And for me, I had been used to taking my sweet  time and just thinking really hard about things, and that's important, but I really  learned to hustle over there, and I think that's come in handy at OpenAI. Okay. So, along these same lines, I asked Kevin Weil, your CPO, what to ask you, and  he said to ask you about this principle of, "Is it maximally accelerated?" Talk about that. That's funny, we have a Slack emoji, apparently, for this now because I used to say that. Now, I  try to paraphrase. Sometimes, I just really want to jump to the punchline of like, "Okay, why  can't we do this now?" or, "Why can't we do it


00:23:39 - 00:24:34
tomorrow?" And I think that it's a good way to cut  through a huge number of blockers with the team and just instill... especially if you come from a  larger company. At some point, we started hiring people from larger tech companies. I think they're  used to, "Let's check in on this in a week," or, "Let's circle back next quarter to see if  we can go on the plan." And I just, as a- ... on the plan and I just kind of as a  thought exercise, always like people asking, "Okay, if this was the most important thing and  you wanted to truly maximally accelerate it, what would you do?" That doesn't mean that you go  do that, but it's really a good forcing function for understanding what's critical path versus what  can happen later. And I've just always felt like execution is incredibly important. These ideas,  they're everywhere. Everyone's talking about a personal AI, you might've seen news on that and  I really think that execution is one of the most


00:24:35 - 00:25:27
important things in the space and this is a tool.  So, it's funny that that became a meme. It's like a little pink Slack emoji that people just put on  whatever they're trying to force the question. I was going to ask, what theme [inaudible  00:24:47]. So, it's a little pink, is there something in there like- It's a Comic Sans emoji that says, is this maximally accelerated? Okay. And so, the kind of the culture there is when someone is working on something,  the push is, is this maximally accelerated? Is there a way we can do this faster?  Is there anything we can unblock? Yeah. And we use that sparingly, right? Because  it needs to be appropriate to the context. There's some things where you don't want to accelerate  as quickly as possible because you kind of want process. And we're very, very deliberate on that  where your process is a tool. And one of the areas where we have an immense amount of process is  safety. Because A, the stakes are already really


00:25:27 - 00:26:21
high, especially with these models, GPT-5 which  is a frontier in so many different ways. But B, if you believe in the exponential, which I  do and most people who work on this stuff do, you have to play practice for a time where you  really, really need the process for sure, sure, sure. And that's why I think it's been really  important to separate out the product development velocity, which has to be super high from, for  things like frontier models, there actually needs to be a rigorous process where you red team, you  work on the system card, you get external input, and then you put things out with confidence  that it's gone through the right safeguards. So, again, it's a nuanced concept, but I found  it very, very useful when we needed and for everything product development, you're a dead on  arrival, so it's important to get stuff out. We got to open source those memes so that  other teams can build on this approach. Absolutely. So, interestingly with ChatGPT,


00:26:21 - 00:27:16
and it's not a surprise, but not only is it the  fastest-growing, most successful consumer product ever, retention is also incredibly high. People  have shared these stats that one month retention is something like 90%, six month retention is  something like 80%. First of all, are these numbers accurate? What can you share there? I'm obviously limited on what exactly I can share, but it is true that our retention numbers  are really exciting and that is actually the thing we look at. We don't care at all how  much time you spend in the product. In fact, our incentive is just to solve your problem and  if you really like the product, you'll subscribe, but there's no incentive to keep you in the  product for long. But we are obviously really, really happy if over the long run, three month  period, et cetera, you're still using this thing. And for me, this was always the elephant  in the room early on. It's like, "Hey, this may be a really cool product, but is this really the  type of thing that you come back to?" And it's


00:27:16 - 00:28:13
been incredible to not just see strong retention  numbers, but just see an improvement in retention over time even as our cohorts become less of an  early adopter and more the average person, so. Yeah. So, that note is something that I  don't think people truly understand how rare this is when a product... The cohort of  users comes, tries it out and then retention over time goes down and then it comes back up,  people come back to it a few months later and use it more. It's called a smiling curve, a  smile curve, and that's extremely rare. Yeah, yeah. Yeah. There's some smiling going  on that's just on the team and I feel like have technology, some of it is not the product.  I think people are actually just getting used to this technology in a really interesting way,  where I find, and this is why the product needs to evolve too, that this idea of delegating to an  AI, it's not natural to most people. It's not like you're going through life and figuring out what  can I delegate? Certain sphere of Silicon Valley


00:28:13 - 00:29:04
does that because they're in a self-optimization  mode and they're trying to delegate everything they can. But I think for most people in the world  it's actually quite unnatural. And you really have to learn, "Okay, what are my goals actually and  what could another intelligence help me with?" And I think that just takes time and people  do figure it out once they've had enough time with the product. But then of course there's been  tons of things that we've done in the product too, whether or not it's making the core models better,  whether or not it's new capabilities like search and personalization and all that kind of  stuff, or just standard growth work too, which we're starting to do. That  stuff matters too, of course. So, you might be answering this question  already, but let me just ask it directly. People may look at this and be like,  "Okay, they're building this kind of layer on top of this God-like intelligence. Of  course it will grow incredibly fast and retention


00:29:04 - 00:29:59
will be incredible. What do you guys actually  doing that sits on top of the model that makes it grow so fast and retain so much?" Is there  something that has worked incredibly well that has moved metrics significantly that you can share? One thing we've learned, I'll answer that question in a minute, but one thing we've learned with  ChatGPT is that there really is no distinction between the model and the product. The model is  the product and therefore you need to iterate on it like a product. And by that I mean obviously  you typically start by shipping something very open-ended, at least if you're OpenAI [inaudible  00:29:38] that's kind of a playbook. But then you really have to look at what are people  trying to do? Okay, they're trying to write, they're trying to code, they're trying to get  advice, they're trying to get recommendations and you need to systematically improve on those  use cases. And that is pretty similar to product development work. Obviously the methodology is a  bit different, but discovery is the same. You got


00:29:59 - 00:30:56
to talk to people, you got to do data science  and you got to try stuff and get feedback. So, that's one chunk of work that we've been  very consciously doing is improving the model on the use cases people care about. And there's also  such thing as vibes because I'm sure you know and that's one of the things that I'm excited about  in GPT-5 is that the vibes are really good. So, that too is, we have a model behavior team and  they really focus on what is the personality of this model and how does it speak and talk. So,  there's that kind of work. I would say that's maybe a third of the retention improvements  that we see or so just roughly. And then I think another third is what I would call product  research capabilities. They're research driven for sure. They have a research component,  but they're really new product features or capabilities. And search is one example of  that where if you remember in the olden days, maybe 20 months ago or something, you would talk  to ChatGPT and it'd be like, "As of my knowledge


00:30:57 - 00:31:53
cut off..." Or, "I can't answer that because that  happened to recently," or something like that. And that is the type of capability  that has been incredibly retentive and for good reason. It just allows you to do more  with the product personalization, like this idea of advanced memory where it can really get to know  you over time is another example of a capability like that. I think that's another good chunk.  And then the third stuff is the stuff you would do in any product and those things exist too.  Not having to log in was a huge hit because it removed a ton of the friction. I think we had  this intuition from the beginning, but we never got to it because we didn't have enough GPU  or other constraint to really go do that. So, there's the traditional product work too. So, I  often think about it as roughly a third, a third, a third, but really we're still learning and we're  planning to evolve the product a ton, which is why I'm sure there's going to be new levers. You mentioned something that I want to come


00:31:53 - 00:32:51
back to real quick. You said that it was  something like 10 days from Hackathon to Sam tweeting about ChatGPT being live? The Hackathon happened much earlier and we were prototyping for a long time, but at some point we  basically ran out of patience on trying to build something more bespoke. And again, that was mostly  because people always wanted to do all this other stuff whenever we tested it. So, it was 10 days  from when we decided we were going to ship to when we shipped. And the research we'd been testing  for a long time, it was kind of an evolution of what we'd called instruction following, which  was the idea that instead of just completing the sentence, these models could actually follow you  instructions. So, if you said summarize this, it would actually do so. And the research had evolved  from that into a chat format where we could do it multi-turn. So, that research took way longer than  10 days and that kind of baking in the background, but the productization of this thing was very,  very fast and lots of things didn't make it in.


00:32:51 - 00:33:44
I remember we didn't have history, which of course  was the first user feedback we got. The model had a bunch of shortcomings and it was so cool to be  able to iterate on the model. The thing I just talked about, treating the model as a product was  not a thing before ChatGPT because we would ship in more hardware where there'd be a release GPT-3  and then we would start working on GPT-4 and these weird giant big spend R&D projects that would  take a really long time and the spec was whatever the spec was and then you'd have to wait another  year. And ChatGPT really broke that down because we were able to make iterative improvements to it  just like software. And really, my dream is that it would be amazing if we could just ship daily  or even hourly like in software land because you could just fix stuff, et cetera. But there's  of course all kinds of challenges in how you do that while keeping the personality intact  while not regressing other capabilities. So, it's an open field to get there. That's such a good example of is it


00:33:44 - 00:34:49
maximally accelerated? Okay, we're  going to ship ChatGPT 10 days. [inaudible 00:33:48]- Holy moly. We've been talking about ChatGPT. Clearly it's kind of a chat interface.  Everyone's always wondering is chat the future of all of this stuff? Interestingly, Kevin Weil  made this really profound point that has always stuck with me when he was on the podcast that chat  is actually a genius interface for building on a super intelligence because it's how we interact  with humans of all variety of intelligence. It scales from someone at the lower end to a super  smart person. And so, it's really valuable as a way to scale this spectrum. Maybe just talk  about that and is chat the long-term interface for ChatGPT, I guess it's called ChatGPT. I feel like we should either drop the chat or drop the GPT at some point because it  is a mouthful. We're stuck with the name, but no matter what we do, the product will  evolve. I think that I agree that there's something profound about natural language. It just  really is the most natural form of communicating


00:34:50 - 00:35:50
to humans and therefore it feels important that  you should be communicating with your software in natural language. I think that's different  from chat though. I think chat was the simplest way to ship at the time. I'm baffled by how much  it took off as a concept. Even more baffled by how many people have copied the paradigm rather  than trying out a different way of interacting with AI. I'm still hoping that will happen.  So, I think natural language is here to stay, but this idea that it has to be a turn-by-turn  chat interaction I think is really limiting. And this is one of the reasons I don't love  the super system analogy, even though we used to always use it is because if you think  that way, then you kind of feel like you're talking to a person and GPT-5 it's amazing  at making great front-end applications. So, I don't see a reason why you wouldn't have AIs  that can render their own UI in some way. And you obviously want to make that predictable and  feel good. But it feels limiting to me to think


00:35:50 - 00:36:50
of the end-all-be-all interface as a chatbot. It  actually kind of feels dystopian almost where I don't want to use all my software through the  proxy of some interface. I love being in Figma, I love being in Google Docs. Those are all  great products to me and they're not chatbots. So, yes on natural language, but no on chat is  where I would describe my point of view. And I'm just hoping in general that we see more consumer  innovation on how people interact with AI because there's so many possibilities and you just got to  try stuff. That's why chat stuck is we just did it and people liked it. So, I'm hoping that we  see more there and we'll try to do our part. So, you mentioned that you kind of got  stuck with this name ChatGPT. Maybe this is part of the answer, but I'm curious just  are there any accidental decisions you guys made early on that have stuck and have  essentially become history changing? There's so many and it is funny, because you have  no time to think about them and then they end up


00:36:50 - 00:37:51
being super consequential. The day was one, we  went from chat with GPT-3.5 to ChatGPT the night before, slightly better but still really bad. What was it called before? It was going to be Chat with GPT-3.5 because we  really didn't think it was going to be successful product. We were trying to actually be as  nerdy as we could about it because that's really what it was. It was a research demo, not  a product. So, we didn't think that was bad. But I think that in the original release, making it  free was a big deal. I don't think we appreciate that because the GPT-3.5 model was in our API for  at least six months prior to that. I think anyone could have built something like this. It might not  have been quite as good on the modeling side, but I think it would've taken off. So, making it free  and putting a nice UI on it, very consequential in the way that you take for granted now. And this is  why I think that A, distribution and the interface are continuously important even in 2025. The paid business, which now it's a giant


00:37:52 - 00:38:52
business both in the consumer space and in the  enterprise space. The birth of that was just to turn away demand originally. It was not like we  brainstormed, "Oh, what is the best monetization model for AI?" It was really what monetization  model or what mechanism would allow us to turn away people who are less serious than the people  who are really trying to use it? And subscriptions just happened to have that property and it grew  into a large business. I think shipping really funky capabilities before they were polished is  another thing where that feels like a tactical decision, but it became a playbook because we  would learn so much. Remember when we shipped Code Interpreter, we learned so much after  we shipped it. Now it's known as I think data analysis in ChatGPT or something like that  just because we actually got real world use cases back that we could then optimize. So, I think  there's been a lot of decisions over time that proved pretty consequential, but we made  them very, very quickly as we have to, so.


00:38:53 - 00:39:44
The $20 a month feels like an  important part of this. Feels like everybody's just doing that now and- On that one actually, I remember I had this kind of panic attack because we really needed to launch  subscriptions because at the time we were taking the product down every time. It was, I don't know  if you remember, we had this fail whale, there's a little [inaudible 00:39:09] generated poem on it.  So, they were like, "We had to get this out." And I remember calling up someone I greatly respect  who's incredible at pricing and I was like, "What should I do?" And we talked a bunch and I  just ran out of time to incorporate most of that feedback. So, what I did do is ship a Google Form  to Discord with, I think the four questions you're supposed to ask on how to price something- [inaudible 00:39:32]? Yeah, exactly. It literally had those four  questions and I remember distinctly A, you [inaudible 00:39:38] a price back and that's kind  of how we got to $20. But B, the next morning,


00:39:44 - 00:40:35
there was a press article on you won't believe  the four genius questions the ChatGPT team asked to price their... It was like if only you knew.  So, there's something about building in this extreme public where people interpret so much  more intentionality into what you're doing than might've actually existed at the time. But we got  with the $20. We're debating something slightly higher at the time. I often wonder what would've  happened because so many other companies ended up copying the $20 price point. So, I'm like, "Did  we erase a bunch of market cap by pressing it this way?" But ultimately I don't care because the more  accessible we can make this stuff, the better. And I think this is the price point that in Western  countries has been reasonable to a lot of people in terms of the value that they get back. And most importantly, we were able to push things down to the free tier semi-regularly and we always  do that when we can [inaudible 00:40:35], but-


00:40:35 - 00:41:28
So, the survey, just to give the official  name, the Van Westendorp survey is how you guys ended up pricing ChatGPT? It was the top Google result. This was before ChatGPT has real-time information.  Otherwise, it could have maybe price itself, but it was Discord plus Google Form plus a blog  post on that methodology that got us there. That is incredible. What a fun story. This  is the survey that Rahul Vohra at Superhuman popularized in his first- round article- Yeah. Yeah, yeah, that's right. That's right. Definitely don't bring me on here as  a pricing expert, I think you have got better people for that. Whether it was right or wrong, it is now the fastest-growing, insane  revenue generating business in the world. So, I wouldn't feel too bad. No, it worked out. Yeah. It worked out. And by the way, I'm on the $200  a month tier, so there's clearly a room- Thank you. Thank you. ... [inaudible 00:41:25]- The story of that one is interesting too because  originally the purpose of the Plus plan was to be


00:41:31 - 00:42:29
able to ship first uptime and then be able to ship  capabilities that we couldn't scale to everyone. And at some point it got so many people in the  Plus tier that had just lost that property. So, the main reason we came up with the $200 tier is  just we had so much incredible research that's actually really, really powerful. Like o3 Pro or  tomorrow GPT-5 Pro and just having a vehicle of shipping that to people who really, really care  is exciting even though it kind of violates the standard way a SaaS page should look, it's  a little jarring to see the 10X jump. So, thank you for being a subscriber on that  and thank you everyone else who's watching you subscribed to any tier, it's great. I'm just going to throw a fishing line into this pond of are there any other stories like  this? You shared this incredible story of Chat with GPT-3.5 being the original name, how you  came up with pricing. Is there anything else? Enterprise is interesting one too because  we've seen so much incredible adoption in the


00:42:30 - 00:43:32
Enterprise and it's sort of objectively crazy to  try to take on building a developer business and a consumer business and an enterprise business  and all at once. But the story there is in like month one or two, it was very clear that most  of the usage was work usage, actually much more than today where you've got so many consumers on  the product and it's kind of sort of transcended into pop culture. But at the time it was writing,  coding, analysis, that kind of stuff. And we were pretty quickly in organically in 90% of Fortune  500 companies in a way that I had seen maybe at Dropbox back when that was my two jobs ago where  we had a similar story. And since then there's been more PLG companies. But the real reason  we did Enterprise, remember we were debating should we do enterprise or should we launch an  iOS app because that's how small the team was. The reason we did is we were starting to get  banned in companies because they all felt rightfully or wrongfully that the privacy and  deployment story, et cetera wasn't there. So,


00:43:32 - 00:44:32
I was just like, "Man, we have to do something.  We're going to miss out on a generational opportunity to build a work product." And  we've literally defined AGI as outperforming most humans at economically valuable work or I'd  probably [inaudible 00:43:45] that, but I think that's the way we put it. And so, I feel like  we had to be present there and it was a fairly quick decision at the time, but it's grown into an  immense business. We just hit 5 million business subscribers up from 3 million, I think a month  or two ago. So, it is kind of the spinoff that it's taking a life of its own that I'm really,  really excited about for [inaudible 00:44:11]- That is a lot to be handling the platform  essentially the API, the consumer product, the fastest-growing, most successful product in  history and also the B2B side, which is clearly a massive business. Do you have any kind of  heuristics for how to make these trade-offs do all this at once and stay sane and be successful?

